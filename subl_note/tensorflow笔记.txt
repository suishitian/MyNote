tensorflow学习笔记

第三章 Tensorflow入门
3.1 Tensorflow计算模型--计算图
  1.张量：Tensor，可以被简单的理解为多维数组。
  2.计算图：Tensorflow中的每一个计算都是计算图上的一个点，而节点之间的边则描述了计算之间的依赖关系。
3.2 计算图的使用
  1.定义阶段：
  eg:
  import tensorflow as tf
  a = tf.constant([1.0,2.0],name="a")
  b = tf.constant([2.0,3.0],name="b")
  result = a+b
  以上代码都在一个计算图上。
  2.不同的计算图上的张量和运算不会共享
  3.与计算图相关的部分API：
    (1)tf.Graph()  ----  生成一个计算图
    eg:g1 = tf.Graph()  ----  生成一个计算图g1
       g1 = tf.Graph()  ----  生成另一个计算图g2
    (2)print(a.graph is tf.get_default_graph())  ----  a为代码前面的一个变量，这句话会print一个Boolean用来判断a是否在默认的计算图上
  4.计算图不仅可以用来隔离张量和计算，还提供了管理张量和计算的机制。
    (1)
      with tf.Session(graph = g1) as sess:  ----  with后面的所有操作都只发生在计算图g1上，其他计算图上的变量不会受到影响
      	tf.initialize_all_variables().run()
      	with tf.variable_scope("",reuse=True)
      		print(sess.run(tf.get_variable("v")))
  5.tf.Graph.device用来指定计算图运行计算的设备(CPU,GPU)
  eg:
    g = tf.Graph()
    with g.device('/gpu:0')
    	result = a+b
3.2  tensorflow数据模型--张量
  3.2.1 张量的概念
    1.张量可以简单的被理解为多维数组。0阶张量可以理解为一个n维数组。但是实际上张量只是tensorflow对运算结果的引用。张量中并没有真正保存数值，保存的是数字的计算过程。
    2.张量的创建：
      a = tf.constant([1.0,2.0],name="a")
      b = tf.constant([1.0,3.0],name="b")
      result = a+b  ----  其中result就是一个张量，此处没有真正计算a+b的值，只是保存了result的计算过程，只是一个引用
    3.张量的三个属性：
      print result
      //Tensor("add:0" ,shape = (2,), dtype=float32)  ----  输出结果
      (1)名字name：第一个属性名字是一个张量的唯一标识符，同样这个名字也代表着张量是如何计算出来的。
         名字规则是node:src_output：计算图上的的node节点上的第src_output个输出(add:0代表add节点上的第1(索引是0)个输出)
      (2)维度shape：描述了张量的维度
      (3)数据类型type：每一个张量会有一个唯一的类型。tensorflow会对所有参与运算的张量进行类型检查，不匹配就会报错
    4.张量的使用
      (1)使用张量记录中间结果：
        a = tf.constant([1.0,2.0],name="a")
      (2)使用张量记录计算过程
        result = a+b
        tf.Session().run(result)  ----  用这个来得到结果，其中result就是张量，储存的是计算过程
3.3 tensorflow运行模型--会话
  1.会话Session是用来执行定义好的运算，可以管理程序运行时的所有资源。
  2.使用会话的两种模式：
    (1)需要明确调用会话生成函数和显示的关闭会话函数：
      sess = tf.Session()  ----  生成会话
      sess.run(...)  ----执行某种操作
      sess.close()  ----  必须显示的关闭该会话
      可以通过with来确保程序一定会正确关闭会话
      with tf.Session() as sess:
      	  sess.run(...)  ----  不需要显示的调用sess.close()，上下文with退出时候会自动关闭和资源释放，只要将所有的计算放在with内部就行了
    (2)手动指定一个默认的会话，然后可以通过tf.Tensor.eval函数来进行计算某个张量的取值
      sess = tf.Session()
      with sess.as_default():
      	  print(result.eval())  ----  使用.eval()来计算张量的值，因为已经指定了默认的会话
    (3)自动将生成的会话注册为默认会话：
      sess = tf.InteractiveSession()  ----  省去指定为默认会话的过程
      print(result.eval())
      sess.close()
    (4)在创建会话的时候进行设置：
      config = tf.ConfigProto(allow_soft_placement = True, log_device_placement=True) 
      sess1 = tf.InteractiveSession(config=config)  ----  两种方式都可以使用config进行设置
      sess2 = tf.Session(config=config)
3.4 tensorflow实现神经网络
  3.4.2 前向传播算法
    1.前向传播算法需要三部分的信息：
      (1)神经网络的输入：就是从实体中提取的特征向量
      (2)神经网络的连接结构：神经元的节点
      (3)每个神经元之间的参数。
    2.神经网络的结构以及边上的权重，就可以求出神经网络的输出：
      [a]=xW  ----  x为神经网络输入，W为对应层的参数矩阵
      [y]=aW  ----  y为输出，a为上一步得到的中间层的结果，W为对应层参数矩阵
  3.4.3 神经网络与tensorflow变量
    1.变量的作用是保存和更新神经网络中的参数
    2.变量的生成
      (1)随机变量：
        weights = tf.Variable(tf.random_normal([2,3],stddev=2))  ----  [2,3]是维数，stddev是标准差，生成的是2*3的高斯分布的随机变量。
      (2)常数变量：
        biases = tf.Variable(tf.zeros([3]))  ----  生成一个初始值全部为0的长度为3的变量
      (3)通过其他变量来设置新变量：
        w2 = tf.Variable(weights.initialized_value()*2.0)  ----  使用weight的初始值的两倍作为w2的值
    3.变量的值在被使用之前，变量的初始化过程需要被明确的调用
    eg:
      w1 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))
      .....
      sess.run(w1.initializer)  ----  显示调用w1的初始化
    4.初始化所有变量：
      init_op = tf.initialize_all_variables()  ----  返回所有的变量
      sess.run(init_op)  ----  对所有变量进行初始化，并且会自动处理变量之间的依赖关系
    5.变量是一种特殊的张量，tf.Variable其实就是一种运算，只不过输出是一个张量。
    6.变量的类型是不可变的，一个变量在构建之后，他的类型就不能再改变了。
  !3.4.4 通过tensorflow训练神经网络模型
    1.每次迭代开始之前，都要先选取一小部分训练数据，叫做batch。通过batch做出的预测与正确结果作比较，得出差距，并且利用反向传播算法更新相应的神经网络参数的取值。
    2.因为每次迭代需要大量的张量计算，为了避免计算图太大，可以使用placeholder。placeholder相当于占位，每次迭代将batch传入placeholder即可。placeholder的类型也是不能改变的。
    eg:
    w1 = tf.Variable(tf.random_normal([2,3],stddev = 1,seed=1))
    w2 = tf.Variable(tf.random_normal([3,1],stddev = 1,seed=1))

    x = tf.placeholder(tf.float32,shape=[3,2],name="input")  ----  用placeholder进行占位
    a = tf.matmul(x,w1)
    y = tf.matmul(a,w2)

    sess = tf.Session()
    init_op = tf.initialize_all_variables()
    sess.run(init_op)

    print(sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]}))  ----  需要提供feed_dict来制定x的值。
    3.损失函数：刻画预测值与真实值的差距
      cross_entropy = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,le-10,1.0)))  ----  交叉熵
      learning_rate = 0.001  ----  学习率
      train_step =\ tf.train.AdamOptimizer(learning_rate).minimize(cross_entroy)
  3.4.5 完整的神经网络程序
    1.完整的程序
    import tensorflow as tf
    from numpy.random import RandomState

    batch_size = 8  ----  设定batch值

    w1 = tf.Variable(tf.random_normal([2,3],stddev = 1,seed = 1))  ----  产生随机w参数值
    w2 = tf.Variable(tf.random_normal([3,1],stddev = 1,seed = 1))

    x = tf.placeholder(tf.float32,shape=[None,2],name="x_input")  ----  设定placeholder
    y_ = tf.placeholder(tf.float32,shape=[None,1],name = "y_input")

    a = tf.matmul(x,w1)  ----  前向传播第一层
    y = tf.matmul(a,w2)  ----  前向传播第二层

    cross_entropy = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))  ----  定义反向传播计算交叉熵的算法
    train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)  ----  定义优化参数的算法

    rdm = RandomState(1)
    dataset_size = 128

    X = rdm.rand(dataset_size,2)  ----  随机生成输入数据
    Y = [[int(x1+x2<1)] for (x1,x2) in X]  ----  正确数据

    with tf.Session() as sess:  ----  开启会话
        init_op = tf.initialize_all_variables()  ----  初始化所有变量
        sess.run(init_op)
        print sess.run(w1)  ----  打印生成的随机参数
        print sess.run(w2)

        STEPS = 5000  ----  迭代次数
        for i in range(STEPS):
            start = (i*batch_size)%dataset_size  ----  根据batch计算完整数据中的起始位置
            end = min(start+batch_size,dataset_size)  ----  结束位置

            sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})  ----  进行训练
            if i%1000 == 0:  ----  每1000次打印交叉熵
                total_cross_entropy = sess.run(cross_entropy,feed_dict={x:X,y_:Y})
                print("After %d training step(s),cross entropy on all data is %g"%(i,total_cross_entropy))
        print sess.run(w1)  ----  跳出循环(训练完毕)之后，打印最终优化之后的两层参数
        print sess.run(w2)
    2.训练神经网络的过程
      (1)定义神经网络的结构和前向传播的输出结果
      (2)定义损失函数以及选择反向传播优化算法
      (3)生成会话(tf.Session())并且在训练数据上反复运行反向传播优化算法

第四章 深层神经网络
4.1 深度学习与深层神经网路
  4.1.2 激活函数实现去线性化
    1.加入偏置项
    2.每个节点的取值(输出)不再是单纯的加权和，而是在输出后面加上一个激活函数：
      (1)ReLU: f(x) = max(x,0)
      (2)sigmoid: f(x) = 1/(1+e^(-x))
      (3)tanh: f(x) = (1-e^(-2x))/(1+e^(-2x))
      (4)tensorflow中的应用：tf.nn.relu,tf.sigmoid,tf.tanh
      (5)自定义激活函数：
        a = tf.nn.relu(tf.matmul(x,w1)+biases1)
  4.1.3 多层网络解决异或运算
4.2 损失函数定义
  4.2.1 经典损失函数
    1.交叉熵
      1.分类问题一般是设置N个输出节点，每一个节点代表一个类别，哪个输出最高则表示分到那一类。期望的输出为[00010000]，就是某一项是0其他都是1
      2.交叉熵：用来评判一个输出向量与期望概率分布的距离(只能用于概率分布)，交叉熵越小代表预测值与真实值的距离越小。所以优化的目标就是让交叉熵尽量小
        H(p,q) = -∑p(x)logq(x)  ----  p是正确答案，q是预测值
      3.如果将分类问题中”一个样例属于某个类别“看成一个概率时间，那么训练数据的正确答案就符合一个概率分布。讲前向传播结果变成一个概率分布的办法就是使用softmax回归。
        (1)softmax是在最后的Output层前面的一个额外的物理层。
        (2)如果原始的输出为y1,y2,y3...,yn。则经过softmax之后的新的输出为：
          softmax(yi) = yi` = e^yi/(∑(j=1~n)e^yj)
        (3)经过处理之后的数据就变成一个概率分布，所以就能够通过交叉熵计算概率分布和真正答案之间的距离了。
        (4)tensorflow中的交叉熵：
          cross_entropy = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))
            ----  y_为正确数据
            ----  tf.clip_by_value可以讲一个张量中的数值限制在一个范围之内，在这里为了避免log0，将其限制在无限接近0和1之间
            ----  tf.log对张量中所有元素一次求对数的功能
            ----  *为普通乘法，即对应元素相乘。矩阵乘法需要使用tf.matmul()
            ----  最后的recude_mean求一个batch中的交叉熵平均值
        (5)使用了softmax回归之后的交叉熵损失函数：
          cross_entropy = tf.nn.softmax_cross_entropy_with_logits(y,y_)  ----  y_正确数据，y预测值
    2.均方误差
      1.回归问题解决的是对数值的预测，这些问题需要的是一个实数，并且神经网络的输出节点往往只有一个输出节点，这个节点的输出值就是预测值。
      2.对于回归问题最常用的就是MSE均方误差：同样越小越好
        MSE(y,y') = (∑(i=1~n)(yi-yi')^2)/n  ----  y为正确答案，yi为正确答案中的一个值，y'是预测值，yi'是某个预测值
      3.tensorflow实现均方误差：
        mse = tf.reduce_mean(tf.square(y_ - y))
          ----  -为普通减法，就是对应元素相减
          ----  y_为正确值
  4.2.2 自定义损失函数 P78

4.3 神经网络优化算法
  1.反向传播算法：训练神经网络的核心算法，给出了一个高效的方式子所有参数上使用梯度下降算法。
  2.梯度下降算法：调整神经网络中参数的取值，主要用于优化单个参数的取值。(反向传播算法会优化梯度下降算法在所有参数中的计算效率)
    eg：J(thet) 是一个损失函数，找到一个参数thet让损失函数的值最小
  3.对于参数thet梯度为δ/δthet(J(thet))，其实就是一个偏导。还需要定义一个学习率n来定义每次参数更新的幅度。
    thet(n+1) = thet(n) - 学习率*偏导
  4.梯度下降算法不能保证会达到全局最优解，有可能得到的是局部最优解。所以参数的初始值非常重要(从哪里开始下降，是局部的坡，还是全局的坡)
  5.梯度下降算法另一个问题就是计算时间太长。为了减少优化时间，使用随机梯度下降算法：在每一轮迭代中，随机优化某一条训练数据上的损失函数。但是随之带来的问题就是，只优化一条数据并不意味着能够使全局损失函数更小，所以有时甚至无法达到局部最优解。
  6.为了综合梯度下降和随机梯度下降的优缺点，使用一个这种的办法，就是每次值计算一小部分数据的损失函数。这一小部分数据被称之为batch。
    (1)batch_size的选取不能太大也不能太小，太小就等于随机梯度下降，可能无法达到最优解，太大就会拖慢运行速度。

4.4 神经网络的进一步优化
  4.4.1 学习率的设置
    1.指数衰减法：
      decayed_learning_rate = learning_rate * decay_rate^(global_step/decay_steps)
        ----  decayed_learning_rate为每一轮优化实际使用的最终学习率
        ----  deay_rate为衰减系数
        ----  decay_step为衰减速度
        ----  global_step为全局的迭代轮数
        ----  还有一个staircase参数，如果选为true会在每完整的过完一边训练数据之后，学习率就减小一次。
    2.tensorflow来设置学习率：
      global_step = tf.Variable(0)
      learning_rate = tf.train.exponential_decay(0.1,global_step,100,0.96,staircase=True)
        ----  0.1 基础学习率
        ----  100 衰减速度(需要global减去这个东西)
        ----  0.96 衰减率(指数的底数)
      其中global_step会在.minimize中自动更新：
        learning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)
          ----  真个函数就是梯度下降算法，输入参数为学习率
          ----  loss为需要优化的损失函数。可以为cross_entropy也可以是MSE
  4.4.2 过拟合问题
    1.对训练数据拟合非常好，对测试数据拟合极差。为了避免过拟合，需要使用正则化。
    2.正则化就是在原来的损失函数上，加上一个刻画复杂的指标。用来限制权重的大小，使得模型不能任意拟合训练数据中的随机噪音。
      L1正则化： R(w) = ||w||1 = ∑|wi|
      L2正则化： R(w) = ||w||^2 = ∑|wi^2|
    3.实际中使用正则化是L1L2一起使用：
      R(w) = ∑(a|wi|+(1-a)wi^2)
    4.tensorflow优化带L2正则化的损失函数：
      w = tf.Variable(tf.random_normal([2,1],stddev = 1,seed = 1))
      y = tf.matmul(x,w)

      loss = tf.reduce_mean(tf.square(y_ - y))+tf.contrib.layer.l2_regularizer(lambda)(w)
        ----  tf.contrib.layer.l2_regularizer输入的是正则化的权重就是a，返回一个函数，返回的函数带进去需要正则化的参数，会最终返回正则化之后的值

    5.使用collection来存储每一个参数的正则化：随着神经网络的复杂，可能有时候网络结构和计算损失函数的部分不在一起。
      P88
  4.4.3 滑动平均模型
    1.每一个变量都另外维护一个影子变量，影子变量的初始值就是相应变量的初始值，每次运行变量更新的时候影子变量的值就会更新为：
      shadow_variable = decay*shadow_variable+(1-delay)*variable
        ----  shadow_variable为影子变量
        ----  variable为待更新的变量
        ----  decay为衰减率
      decay决定了模型更新的速度，decay越大模型就越趋于稳定。实际应用中，一般将decay设定为非常接近1的数字，为了让模型在前期可以更新的更快
    2.ExponentialMovingAverage提供了num_updates参数来动态设置decay的大小：
      衰减率将会是：min{decay,(1+num_updates)/(10+nu_updates)}  ----  也就是decay和另一个参数中更小的东西
    3.tensowflow实现滑动平均模型
      P90
      step = tf.Variable(0,trainable=false)
      ema = ef.train.ExpoenetialMovingAverage(0.99,step)
      maintain_averages_op = ema.apply([v1])  ----  对v1数据进行滑动平均，即只要v1中的值发生变化，v1的影子变量也会变化
      ......
      print sess.run([v1,ema.average(v1)])  ----  之后想要获取v1的滑动平均变量的时候只需要使用ema.average()即可

第五章 MNIST数字识别问题
5.1 MNIST数据处理
5.2 Tensorflow训练神经网络
  5.2.1 TensorFLow训练神经网络
    import tensorflow as tf
    from tensorflow.examples.tutorials.mnist import input_data    

    #
    INPUT_NODE = 784  ----  输入节点个数
    OUTPUT_NODE = 10  ----  输出节点个数，代表了10种分类    

    LAYER_NODE = 500  ----  中间层的节点个数    

    BATCH_SIZE = 100  ----  batch_size    

    LEARNING_RATE_BASE = 0.8  ----  基础学习率
    LEARNING_RATE_DECAY = 0.99  ----  学习率的衰减率(指数的底数)
    REGULARIZATION_RATE = 0.0001  ----  正则化权重
    TRAINING_STEPS = 10000  ----  总的迭代次数
    MOVING_AVERAGE_DECAY = 0.99  ----  平均滑动衰减率
    #
    def inference(input_tensor,avg_class,weights1,biases1,weights2,biases2):  ----  定义了一个前向传播算法函数，直接从输入节点计算到输出节点的结果
        if avg_class == None:  ----  如果没有传入滑动平均类，即计算普通的变量更新
            layer1 = tf.nn.relu(tf.matmul(input_tensor,weights1)+biases1)  ----  第一层的结果(带偏置量)，并且激活函数为ReLU
            return tf.matmul(layer1,weights2)+biases2  ----  output的计算，这里没有使用Relu是因为在计算交叉熵的时候会自动使用softmax所以这里没有加入激活函数
        else:
            layer1 = tf.nn.relu(tf.matmul(input_tensor,avg_class.average(weights1))+avg_class.average(biases1))
            return tf.matmul(layer1,avg_class.average(weights2))+avg_class.average(biases2)
    #
    def train(mnist):  ----  定义了整个训练的过程
      #placeholder
      x = tf.placeholder(tf.float32,[None,INPUT_NODE],name="x-input")  ----  定义placeholder
      y_ = tf.placeholder(tf.float32,[None,OUTPUT_NODE],name="y-input")    

      weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE,LAYER_NODE],stddev=0.1))  ----  随机生成第一层参数，以及偏置量
      biases1 = tf.Variable(tf.constant(0.1,shape=[LAYER_NODE]))    

      weights2 = tf.Variable(tf.truncated_normal([LAYER_NODE,OUTPUT_NODE],stddev=0.1))  ----  随机生成第二层参数，以及偏置量
      biases2 = tf.Variable(tf.constant(0.1,shape=[OUTPUT_NODE]))    

      global_step = tf.Variable(0,trainable=False)  ----  全局步数，会在.minimize()中自动+1
      #
      y = inference(x,None,weights1,biases1,weights2,biases2)  ----  计算前向传播的结果，也就是预测值
      #
      variable_average = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)  ----  滑动平均
      variables_averages_op = variable_average.apply(tf.trainable_variables())  ----  对所有可训练的数据都进行滑动平均
      #
      average_y = inference(x,variable_average,weights1,biases1,weights2,biases2)  ----  输入了滑动平均类的前向传播结果
      #
      cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y,labels = tf.argmax(y_,1))  ----  交叉熵(因为结果是概率分布)，且自动加入了softmax层
      cross_entropy_mean = tf.reduce_mean(cross_entropy)    

      #
      regu = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)  ----  L2正则化
      regu_total = regu(weights1) + regu(weights2)  ----  两层正则化的和
      #
      loss = cross_entropy_mean+regu_total  ----  完整的损失函数

      learning_rate = tf.train.exponential_decay(  ----  指数衰减的学习率
        LEARNING_RATE_BASE,
        global_step,
        mnist.train.num_examples/BATCH_SIZE,
        LEARNING_RATE_DECAY)
    #
      train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)  ----  优化函数，梯度下降
      with tf.control_dependencies([train_step,variables_averages_op]):
        train_op = tf.no_op(name='train')    

      correct_prediction = tf.equal(tf.argmax(average_y,1),tf.argmax(y_,1))
      correct_prediction_noa = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))
      accuary = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
      accuary_noa = tf.reduce_mean(tf.cast(correct_prediction_noa,tf.float32))
      
      with tf.Session() as sess :
        tf.initialize_all_variables().run()
        validate_feed = {x:mnist.validation.images,
              y_:mnist.validation.labels}
        test_feed = {x:mnist.test.images, y_:mnist.test.labels}
            

        for i in range(TRAINING_STEPS):  ----  训练过程
          if i%1000==0:
            validate_acc= sess.run(accuary,feed_dict = validate_feed)
            print("After %d training steps, validation accuracy using average model is %g"
              %(i,validate_acc))
          xs,ys = mnist.train.next_batch(BATCH_SIZE)
          sess.run(train_op,feed_dict={x:xs,y_:ys})
        
        test_acc = sess.run(accuary,feed_dict=test_feed)
        print("After %d training steps, test accuracy using average model is %g"
            %(TRAINING_STEPS,test_acc))
      print "over"

    def main(atgv = None):
      mnist = input_data.read_data_sets("tmp/data",one_hot=True)
      train(mnist)    

    if __name__ == '__main__':
      tf.app.run();
  5.2.2 使用验证数据集判断模型效果
    交叉验证：讲一个数据分为k分，其中的一份用作测试数据，剩余的k-1份用作训练。然后重复k次，让每一份k得到验证，就是交叉验证
  5.2.3 不同模型的效果比较
    P102

5.3 变量管理
  1.tensorflow中提供了通过变量名称来创建或者获取一个变量的机制。通过这个机制可以在不同函数中直接通过获取变量的名字来使用变量。而不需要将变量通过参数的形式到处传递。主要是通过tf.get_variable和tf.variable_scope实现的
  2.用tf.get_variable和tf.Variable创建变量
    v = tf.get_variable("v",shape=[1],initializer=tf.constant_initializer(1.0))  ----  这两句几乎没有区别
    v = tf.Variable(tf.constant(1.0,shape=[1],name="v"))
  3.用tf.get_variable生成变量时候，如果变量名已经定义过，就会报错。想用get_variable获取变量，则需要使用tf.variable_scope生成一个上下文
    with tf.Variable_scope("foo"):
      v = tf.get_variable("v",[1],initializer = tf.constant_initializer(1.0))
    with tf.Variable_scope("foo"):
      //v = tf.get_variable("v",1)  ----  这一句会报错，因为上面已经在foo命名空间中间定义过v了，重复定义会报错
    with tf.Variable_scope("foo",reuse=True):  ----  如果在生成命名空间的时候加上reuse=True，则会直接获取已经声明了的变量
      v1 = tf.get_variable("v",[1])  ----  获取已经声明过的v
      print v==v1  ----  输出为true
    with tf.variable_scope("bar",reuse=True):  ----  将参数设置为reuse=true时候，则只能获取已经声明过的变量
      v = tf.get_variable("v",1)  ----  报错，因为v在bar中没有声明过
  4.scope可以嵌套：内层如果不指定，则reuse跟随外层
    with tf.bariable_scope("root"):  ----  最外层不指定为false
      with tf.variable_scope("foo",reuse=True)
        ...
        with tf.variable_scope("bar")  ----  这里的reuse为True,不指定就跟随外层
      ....  ----  回到这里之后，又为false
  5.使用scope管理变量：在命名空间中创建的变量都会带上这个命名空间名作为前缀
    v1 = tf.get_variable("v",[1])
    print v1.name  ----  输出v:0

    with tf.variable_scope("foo"):
      v2 = tf.get_variable("v",[1])
      print v2.name  ----  输出foo/v:0

    with tf.variable_scope("foo"):
      with tf.variable_scope("bar"):
        v3 = tf.get_variable("v",[1])
        print v3.name  ----  输出foo/bar/v:0
    with tf.variable_scope("",reuse = True)
      v4 = tf.get_variable("foo/bar/v",[1])  ----  也可以直接制定命名空间
    print v4==v3  ----  True
  6.使用命名空间改进前向传播函数inference:

    def inference(input_tensor,reuse=False):  ----  第一次调用使用false，用来生成变量，计算的时候使用True用来直接获取变量
      with tf.variable_scope('layer1',reuse=reuse):
          weights = tf.get_variable("weights",[INPUT_NODE,LAYER1_NODE],initializer=tf.truncated_normal_initializer(stddev=))
          biases = tf.get_variable("biases",[LAYER1_NODE]，initializer=tf.constant_initializer(0.0))
          layer1 = tf.nn.relu(tf.matmul(input_tensor,weights)+biases)
      with tf.variable_scope('layer2',reuse=reuse):
          weights = tf.get_variable("weights",[LAYER1_NODE,OUTPUT_NODE],initializer=tf.truncated_normal_initializer(stddev=))
          biases = tf.get_variable("biases",[OUTPUT_NODE]，initializer=tf.constant_initializer(0.0))
          layer2 = tf.matmul(input_tensor,weights)+biases
      return layer

5.4 TensorFlow模型持久化：
  5.4.1 持久化代码实现
    1.使用tf.train.Saver()来保存模型
      import tensorflow as tf
        v1 = tf.Variable(tf.constant(1.0,shape=[1],name="v1"))
        v2 = tf.Variable(tf.constant(2.0,shape=[1],name="v2"))
        result = v1+v2      
        init_op = tf.initialize_all_variables()       
        saver = tf.train.Saver()  ----  单纯为了获取一个Saver对象
        with tf.Session() as sess:
            sess.run(init_op)
            saver.save(sess,"model.ckpt")  ----  要注意，保存的时候，会话也作为输入参数
    2.Saver会在目录下生成三个文件：
      (1)model.ckpt.meta:保存了tensorflow的计算图的结构
      (2)model.ckpt:保存了程序中每一个变量的取值
      (3)checkpoint:后面会详细讲解
    3.使用tf.train.Saver()来恢复模型：
      import tensorflow as tf
      saver = tf.train.import_meta_graph("model.ckpt.meta")  ----  恢复数据
      with tf.Session() as sess:
        saver.restore(sess,"model.ckpt")  ----  恢复计算图
        print sess.run(tf.get_default_graph().get_tensor_by_name("add:0"))  ----  计算计算图中的某个节点的输出值

